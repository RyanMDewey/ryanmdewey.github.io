---
layout: post
title: "Building AI on Bare-Metal with NEON Kernels"
date: 2024-04-18
---

I’ve spent the last few weeks optimizing low-level matrix multiplication using FP16 NEON assembly on the Raspberry Pi 5:

- ✅ Achieved 6ms inference on 1024×1024 matrices  
- 🔗 Integrated into the ORC compiler backend  
- ⚙️ Benchmarked against LLVM, GCC, and Strassen’s  

> Next up? [Self-modifying AI-aware kernels.](#)
